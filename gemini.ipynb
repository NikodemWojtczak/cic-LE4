{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask version: 2025.5.1\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Project Setup and Imports\n",
    "# Description: Import necessary libraries for data manipulation, Dask, machine learning, and utilities.\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from dask_ml.linear_model import LinearRegression as DaskLinearRegression\n",
    "from dask_ml.preprocessing import StandardScaler as DaskStandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging  # <<< Add this import\n",
    "\n",
    "# Ensure reproducibility for data generation\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"Dask version: {dask.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed existing Dask client and cluster.\n",
      "Dask Client created: <Client: 'tcp://127.0.0.1:58355' processes=7 threads=14, memory=48.00 GiB>\n",
      "Dask Dashboard link: http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Dask Configuration and Client Initialization\n",
    "# Description: Set up a Dask LocalCluster and Client for distributed computation.\n",
    "# This allows you to monitor computations via the Dask dashboard.\n",
    "\n",
    "# Close existing clusters/clients if any, to ensure a fresh start\n",
    "try:\n",
    "    if \"client\" in locals() and client:  # Check if client exists and is not None\n",
    "        client.close()\n",
    "    if \"cluster\" in locals() and cluster:  # Check if cluster exists and is not None\n",
    "        cluster.close()\n",
    "    print(\"Closed existing Dask client and cluster.\")\n",
    "except NameError:\n",
    "    print(\"No existing Dask client/cluster to close (NameError).\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while closing existing Dask setup: {e}\")\n",
    "\n",
    "\n",
    "# Option 1: Let Dask manage the number of workers and threads (typically based on your CPU cores)\n",
    "cluster = LocalCluster(silence_logs=logging.ERROR)  # <<< Corrected line\n",
    "# Option 2: Explicitly set workers and threads (example: 4 workers, 2 threads each)\n",
    "# cluster = LocalCluster(n_workers=4, threads_per_worker=2, silence_logs=logging.ERROR) # <<< Corrected line\n",
    "\n",
    "client = Client(cluster)\n",
    "print(f\"Dask Client created: {client}\")\n",
    "print(f\"Dask Dashboard link: {client.dashboard_link}\")\n",
    "\n",
    "# You can access the dashboard by navigating to the link printed above in your web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"dask_project_data\"\n",
    "N_FILES = 5  # Number of CSV files to generate\n",
    "N_ROWS_PER_FILE = 6_000_000  # Number of rows per file\n",
    "N_FEATURES = 10  # Number of features (excluding the target)\n",
    "TARGET_NOISE_LEVEL = 0.1  # Noise level for the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5 data files in 'dask_project_data'...\n",
      "Generated dask_project_data/data_part_00.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Data Generation\n",
    "# Description: Generate a moderately large dataset (aiming for ~5GB).\n",
    "# The data will be tabular, with numerical features and a target variable for regression.\n",
    "# It will be saved as multiple CSV files, which Dask handles well.\n",
    "\n",
    "DATA_DIR = \"dask_project_data\"\n",
    "N_FILES = 5  # Number of CSV files to generate\n",
    "N_ROWS_PER_FILE = 6_000_000  # Number of rows per file\n",
    "N_FEATURES = 10  # Number of features (excluding the target)\n",
    "TARGET_NOISE_LEVEL = 0.1  # Noise level for the target variable\n",
    "\n",
    "# Total rows = N_FILES * N_ROWS_PER_FILE\n",
    "# Estimated size: (N_FEATURES + 1 target) * 8 bytes/float * Total_rows\n",
    "# (10 + 1) * 8 bytes/float * (10 * 6,000,000) rows = 11 * 8 * 60,000,000 bytes\n",
    "# = 88 * 60,000,000 bytes = 5,280,000,000 bytes\n",
    "# 5,280,000,000 / (1024**3)  ~= 4.9 GB. This fits the requirement.\n",
    "\n",
    "\n",
    "def generate_data_chunk(num_rows, num_features, file_idx):\n",
    "    \"\"\"Generates a chunk of data and saves it to a CSV file.\"\"\"\n",
    "    data = pd.DataFrame(\n",
    "        np.random.rand(num_rows, num_features),\n",
    "        columns=[f\"feature_{i}\" for i in range(num_features)],\n",
    "    )\n",
    "\n",
    "    # Create a target variable based on a linear combination of features plus noise\n",
    "    # Example: target = 0.5*f0 + 1.2*f1 - 0.8*f2 + ... + noise\n",
    "    coeffs = np.random.rand(num_features) * 2 - 1  # Coefficients between -1 and 1\n",
    "    true_signal = np.zeros(num_rows)\n",
    "    for i in range(num_features):\n",
    "        true_signal += coeffs[i] * data[f\"feature_{i}\"]\n",
    "\n",
    "    noise = TARGET_NOISE_LEVEL * np.random.randn(num_rows)\n",
    "    data[\"target\"] = true_signal + noise\n",
    "\n",
    "    filepath = os.path.join(DATA_DIR, f\"data_part_{file_idx:02d}.csv\")\n",
    "    data.to_csv(filepath, index=False)\n",
    "    return filepath\n",
    "\n",
    "\n",
    "if os.path.exists(DATA_DIR):\n",
    "    print(\n",
    "        f\"Data directory '{DATA_DIR}' already exists. Skipping generation if files are present.\"\n",
    "    )\n",
    "    # Check if files exist, if not, create dir and generate\n",
    "    expected_files = [\n",
    "        os.path.join(DATA_DIR, f\"data_part_{i:02d}.csv\") for i in range(N_FILES)\n",
    "    ]\n",
    "    if all(os.path.exists(f) for f in expected_files):\n",
    "        print(f\"{N_FILES} data files found. Using existing data.\")\n",
    "    else:\n",
    "        shutil.rmtree(DATA_DIR)  # Clean up incomplete data\n",
    "        os.makedirs(DATA_DIR, exist_ok=True)\n",
    "        print(f\"Generating {N_FILES} data files in '{DATA_DIR}'...\")\n",
    "        for i in range(N_FILES):\n",
    "            path = generate_data_chunk(N_ROWS_PER_FILE, N_FEATURES, i)\n",
    "        print(f\"Data generation complete.\")\n",
    "else:\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    print(f\"Generating {N_FILES} data files in '{DATA_DIR}'...\")\n",
    "    for i in range(N_FILES):\n",
    "        path = generate_data_chunk(N_ROWS_PER_FILE, N_FEATURES, i)\n",
    "        print(f\"Generated {path}\")\n",
    "    print(f\"Data generation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = os.path.join(DATA_DIR, \"data_part_*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define Data Loading and Preprocessing Pipeline\n",
    "# Description: Load data using Dask DataFrame and apply transformations.\n",
    "# Transformations:\n",
    "# 1. Create an interaction feature: feature_A = feature_0 * feature_1\n",
    "# 2. Create a polynomial feature: feature_B = feature_2 ** 2\n",
    "# 3. Scale all features using DaskStandardScaler.\n",
    "\n",
    "import dask.array as da  # Ensure dask.array is imported\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(file_pattern):\n",
    "    \"\"\"Loads and preprocesses the data using Dask.\"\"\"\n",
    "    ddf = dd.read_csv(file_pattern)\n",
    "\n",
    "    print(f\"Number of partitions in loaded ddf: {ddf.npartitions}\")\n",
    "    # print(\"Sample of loaded data (ddf.head()):\")\n",
    "    # print(ddf.head())\n",
    "\n",
    "    # Transformation 1: Interaction feature\n",
    "    ddf[\"interaction_feature\"] = ddf[\"feature_0\"] * ddf[\"feature_1\"]\n",
    "\n",
    "    # Transformation 2: Polynomial feature\n",
    "    ddf[\"polynomial_feature\"] = ddf[\"feature_2\"] ** 2\n",
    "\n",
    "    feature_columns = [col for col in ddf.columns if col != \"target\"]\n",
    "    X_df = ddf[feature_columns]  # This is a Dask DataFrame\n",
    "    y_series = ddf[\"target\"]  # This is a Dask Series\n",
    "\n",
    "    # Transformation 3: Scale features\n",
    "    scaler = DaskStandardScaler()\n",
    "    X_scaled_da = scaler.fit_transform(X_df)  # This returns a Dask Array\n",
    "\n",
    "    # Convert y_series (Dask Series) to a Dask Array\n",
    "    # lengths=True can be more efficient if partition lengths are known/computable\n",
    "    # For a single series, just .to_dask_array() is often sufficient.\n",
    "    y_da = y_series.to_dask_array(lengths=True)\n",
    "\n",
    "    # Ensure y_da is 1D (e.g., (n_samples,)) not (n_samples, 1))\n",
    "    if y_da.ndim > 1 and y_da.shape[1] == 1:\n",
    "        y_da = y_da.ravel()  # Or y_da.squeeze() if you are sure it's (N,1)\n",
    "    elif y_da.ndim == 0:  # Handle scalar case if it somehow occurs\n",
    "        y_da = y_da.reshape(\n",
    "            1,\n",
    "        )\n",
    "\n",
    "    print(f\"Type of X returned by load_and_preprocess_data: {type(X_scaled_da)}\")\n",
    "    if isinstance(X_scaled_da, da.Array):\n",
    "        print(f\"   X dtype: {X_scaled_da.dtype}, X chunks: {X_scaled_da.chunks}\")\n",
    "    print(f\"Type of y returned by load_and_preprocess_data: {type(y_da)}\")\n",
    "    if isinstance(y_da, da.Array):\n",
    "        print(f\"   y dtype: {y_da.dtype}, y chunks: {y_da.chunks}\")\n",
    "\n",
    "    return X_scaled_da, y_da, feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define Machine Learning Task (Regression)\n",
    "# Description: Perform a regression task using Dask-ML.\n",
    "# This includes splitting data, training a model, making predictions, and evaluating.\n",
    "\n",
    "\n",
    "def run_ml_task(X, y):\n",
    "    \"\"\"Runs the machine learning regression task.\"\"\"\n",
    "    # X and y are expected to be Dask Arrays from load_and_preprocess_data\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True, convert_mixed_types=True\n",
    "    )\n",
    "\n",
    "    # Initialize and train the Dask-ML Linear Regression model\n",
    "    model = DaskLinearRegression()\n",
    "\n",
    "    print(\"Starting model training...\")\n",
    "    print(f\"Type of X_train before fit: {type(X_train)}\")\n",
    "    if isinstance(X_train, da.Array):\n",
    "        print(f\"   X_train dtype: {X_train.dtype}, X_train chunks: {X_train.chunks}\")\n",
    "    elif isinstance(X_train, dd.DataFrame):\n",
    "        print(f\"   X_train is unexpectedly a Dask DataFrame!\")\n",
    "\n",
    "    print(f\"Type of y_train before fit: {type(y_train)}\")\n",
    "    if isinstance(y_train, da.Array):\n",
    "        print(f\"   y_train dtype: {y_train.dtype}, y_train chunks: {y_train.chunks}\")\n",
    "    elif isinstance(y_train, dd.Series):\n",
    "        print(f\"   y_train is unexpectedly a Dask Series!\")\n",
    "\n",
    "    # .fit() on Dask collections will trigger computations\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"Making predictions...\")\n",
    "    model.predict(X_test)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Sequential Benchmark (Dask with Single Worker/Thread for Dashboard)\n",
    "# Description: Run the full pipeline using Dask's distributed scheduler\n",
    "# configured with a single worker and single thread to establish a baseline\n",
    "# while still allowing dashboard access.\n",
    "\n",
    "print(\"\\n--- Starting Sequential Benchmark (Single Worker/Thread for Dashboard) ---\")\n",
    "\n",
    "# Ensure any existing Dask client/cluster is shut down\n",
    "# This is important to avoid conflicts with the new sequential_cluster\n",
    "try:\n",
    "    if \"client\" in locals() and client and client.status != \"closed\":\n",
    "        client.close()\n",
    "        print(\"Closed existing global Dask client.\")\n",
    "    if \"cluster\" in locals() and cluster and cluster.status != \"closed\":\n",
    "        cluster.close()\n",
    "        print(\"Closed existing global Dask cluster.\")\n",
    "except NameError:\n",
    "    pass  # No client/cluster was active\n",
    "except Exception as e:\n",
    "    print(f\"Error closing pre-existing Dask client/cluster: {e}\")\n",
    "\n",
    "# Configure and start a Dask LocalCluster for sequential-like execution\n",
    "# This cluster will have 1 worker and 1 thread per worker.\n",
    "sequential_cluster = None\n",
    "sequential_client = None\n",
    "try:\n",
    "    sequential_cluster = LocalCluster(\n",
    "        n_workers=1,\n",
    "        threads_per_worker=1,\n",
    "        silence_logs=logging.ERROR,  # Make sure 'logging' is imported\n",
    "    )\n",
    "    sequential_client = Client(sequential_cluster)\n",
    "    print(f\"Sequential Dask Client (1 worker, 1 thread) created: {sequential_client}\")\n",
    "    print(f\"Dashboard for sequential run: {sequential_client.dashboard_link}\")\n",
    "    print(\"You can open this dashboard link to observe the 'sequential' execution.\")\n",
    "\n",
    "    start_time_seq = time.time()\n",
    "\n",
    "    # Run the full pipeline\n",
    "    print(\"Loading and preprocessing data (sequentially via single worker)...\")\n",
    "    # Pass the client if your functions are designed to use an explicit client,\n",
    "    # otherwise, Dask will use the active global client (sequential_client here).\n",
    "    X_seq, y_seq, feature_cols_seq = load_and_preprocess_data(file_pattern)\n",
    "\n",
    "    print(\"Running ML task (sequentially via single worker)...\")\n",
    "    model_seq = run_ml_task(X_seq, y_seq)\n",
    "\n",
    "    end_time_seq = time.time()\n",
    "    sequential_duration = end_time_seq - start_time_seq\n",
    "\n",
    "    print(f\"\\nSequential Benchmark Complete.\")\n",
    "    print(\n",
    "        f\"Total time taken (Dask single worker/thread): {sequential_duration:.2f} seconds\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the sequential benchmark: {e}\")\n",
    "    # Ensure sequential_duration is set if an error occurs before its calculation\n",
    "    if \"start_time_seq\" in locals():\n",
    "        sequential_duration = time.time() - start_time_seq\n",
    "    else:\n",
    "        sequential_duration = -1  # Indicate an error or that it didn't run\n",
    "\n",
    "finally:\n",
    "    # IMPORTANT: Shut down the sequential client and cluster\n",
    "    if sequential_client:\n",
    "        try:\n",
    "            sequential_client.close()\n",
    "            print(\"Sequential Dask client closed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error closing sequential Dask client: {e}\")\n",
    "    if sequential_cluster:\n",
    "        try:\n",
    "            sequential_cluster.close()\n",
    "            print(\"Sequential Dask cluster closed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error closing sequential Dask cluster: {e}\")\n",
    "\n",
    "# Reset Dask configuration to a sensible default for any operations\n",
    "# that might not explicitly use a client later, though Cell 7 (Parallel Benchmark)\n",
    "# will create its own specific cluster and client.\n",
    "dask.config.set(scheduler=\"threads\")  # Default for many Dask collections if no client\n",
    "print(\"Dask config reset to 'threads' scheduler as a general default.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Parallel Benchmark (Dask with LocalCluster)\n",
    "# Description: Run the full pipeline using a Dask LocalCluster for parallel execution.\n",
    "# Compare its performance against the sequential benchmark.\n",
    "\n",
    "print(\"\\n--- Starting Parallel Benchmark ---\")\n",
    "\n",
    "# Re-initialize Dask client and cluster for parallel execution\n",
    "try:\n",
    "    if \"client\" in locals() and client:\n",
    "        client.close()\n",
    "    if \"cluster\" in locals() and cluster:\n",
    "        cluster.close()\n",
    "except NameError:\n",
    "    pass\n",
    "except Exception as e:\n",
    "    print(f\"Error closing Dask client/cluster: {e}\")\n",
    "\n",
    "\n",
    "# Use the cluster settings from Cell 2 or define new ones\n",
    "# cluster = LocalCluster(n_workers=4, threads_per_worker=2, silence_logs=logging.ERROR) # <<< Corrected line\n",
    "cluster = LocalCluster(\n",
    "    silence_logs=logging.ERROR\n",
    ")  # <<< Corrected line (Or default, as in Cell 2)\n",
    "client = Client(cluster)\n",
    "print(f\"Dask Client for parallel run: {client}\")\n",
    "print(f\"Dashboard link for parallel run: {client.dashboard_link}\")\n",
    "print(\"Please open the Dask Dashboard to observe the parallel execution.\")\n",
    "\n",
    "start_time_parallel = time.time()\n",
    "\n",
    "# Run the full pipeline\n",
    "print(\"Loading and preprocessing data (in parallel)...\")\n",
    "X_parallel, y_parallel, feature_cols_parallel = load_and_preprocess_data(file_pattern)\n",
    "\n",
    "print(\"Running ML task (in parallel)...\")\n",
    "model_parallel = run_ml_task(X_parallel, y_parallel)\n",
    "\n",
    "end_time_parallel = time.time()\n",
    "parallel_duration = end_time_parallel - start_time_parallel\n",
    "\n",
    "print(f\"\\nParallel Benchmark Complete.\")\n",
    "print(f\"Total time taken (parallel Dask): {parallel_duration:.2f} seconds\")\n",
    "\n",
    "# Performance Comparison\n",
    "print(\"\\n--- Performance Comparison ---\")\n",
    "print(f\"Sequential execution time: {sequential_duration:.2f} seconds\")\n",
    "print(f\"Parallel execution time: {parallel_duration:.2f} seconds\")\n",
    "if (\n",
    "    parallel_duration > 0 and sequential_duration > 0\n",
    "):  # ensure sequential_duration is also positive\n",
    "    speedup = sequential_duration / parallel_duration\n",
    "    print(f\"Speedup: {speedup:.2f}x\")\n",
    "else:\n",
    "    print(\n",
    "        \"Parallel or sequential execution was too fast, zero, or an error occurred, cannot calculate speedup.\"\n",
    "    )\n",
    "\n",
    "# Plotting the results\n",
    "times = [sequential_duration, parallel_duration]\n",
    "labels = [\"Sequential (Dask Single-Threaded)\", \"Parallel (Dask LocalCluster)\"]\n",
    "\n",
    "if sequential_duration > 0 and parallel_duration > 0:  # Only plot if times are valid\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x=labels, y=times)\n",
    "    plt.title(\"Benchmark: Sequential vs. Parallel Execution Time\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.xticks(rotation=15, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping plot due to invalid execution times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Dask Dashboard Analysis and Task Graph Visualization (Guidance)\n",
    "# Description: This cell provides guidance on what to analyze using the Dask dashboard\n",
    "# and how to interpret task graphs. You should take screenshots from your dashboard\n",
    "# during the parallel benchmark run for your report.\n",
    "\n",
    "# --- Guidance for your Report ---\n",
    "\n",
    "# 1. Task Execution Timeline (Stream Plot on Dashboard):\n",
    "#    - Observe how tasks are distributed across workers and threads.\n",
    "#    - Look for periods of high activity (many tasks running in parallel) vs. idle time.\n",
    "#    - Identify which stages of your pipeline (e.g., read_csv, feature engineering, scaling, model fitting)\n",
    "#      correspond to different patterns on the timeline.\n",
    "#    - Colors on the stream plot often indicate different types of operations (e.g., I/O, compute).\n",
    "\n",
    "# 2. Worker Load Balance (Workers Tab -> Memory, CPU, Network):\n",
    "#    - Check if memory usage is evenly distributed or if some workers are overburdened (potential for OOM errors).\n",
    "#    - Monitor CPU utilization across workers. Are all workers actively contributing?\n",
    "#    - Observe network traffic, especially during data loading and shuffling phases.\n",
    "#    - Imbalances can indicate poor data partitioning or tasks that are hard to parallelize.\n",
    "\n",
    "# 3. Graph Structure (Graph Tab or from `.visualize()`):\n",
    "#    - Examine the Dask task graph. It shows the dependencies between tasks.\n",
    "#    - Large, wide graphs indicate high potential for parallelism.\n",
    "#    - Long, narrow \"bottleneck\" chains in the graph limit parallelism. These are critical paths.\n",
    "#    - The complexity of the graph (number of nodes and edges) gives an idea of Dask's overhead in managing tasks.\n",
    "#    - Example: (You can run this for specific Dask collections to see their graph)\n",
    "#      if 'X_parallel' in locals(): # check if X_parallel exists\n",
    "#          X_parallel.visualize(filename='X_parallel_graph.png') # Requires graphviz\n",
    "#          print(\"Task graph for X_parallel saved to 'X_parallel_graph.png'\")\n",
    "#          # Or view a small part if the graph is too big:\n",
    "#          # (X_parallel.feature_0 + X_parallel.feature_1).visualize()\n",
    "\n",
    "# To take screenshots:\n",
    "# - Run the parallel benchmark (Cell 7).\n",
    "# - While it's running, open the Dask dashboard (link provided when client starts).\n",
    "# - Navigate to relevant tabs (Status, Workers, Graph, Profile) and capture images.\n",
    "# - Focus on periods where significant computation is happening.\n",
    "\n",
    "# You would include these screenshots in your report and discuss your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Experimenting with Dask Task Graph Design (Guidance & Example)\n",
    "# (Ensure client and cluster from Cell 7 are active and healthy, or restart them)\n",
    "\n",
    "# ... (ensure client is set up as in Cell 7) ...\n",
    "# if 'client' not in locals() or not client or client.status == 'closed':\n",
    "#     print(\"Client not running or closed. Restarting client and cluster for experiment.\")\n",
    "#     if 'cluster' in locals() and cluster:\n",
    "#         try: cluster.close()\n",
    "#         except Exception: pass\n",
    "#     cluster = LocalCluster(silence_logs=logging.ERROR)\n",
    "#     client = Client(cluster)\n",
    "#     print(f\"Re-initialized Dask Client: {client}\")\n",
    "#     print(f\"Dashboard: {client.dashboard_link}\")\n",
    "\n",
    "\n",
    "def pipeline_with_strategic_persist(file_pattern):  # Renamed for clarity\n",
    "    print(\"Running pipeline with strategic .persist()...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    ddf_loaded = dd.read_csv(file_pattern)  # Load fresh\n",
    "\n",
    "    # Initial transformations (these are lazy)\n",
    "    ddf_transformed = ddf_loaded.assign(\n",
    "        interaction_feature=ddf_loaded[\"feature_0\"] * ddf_loaded[\"feature_1\"],\n",
    "        polynomial_feature=ddf_loaded[\"feature_2\"] ** 2,\n",
    "    )\n",
    "\n",
    "    feature_columns = [\n",
    "        col\n",
    "        for col in ddf_transformed.columns\n",
    "        if col != \"target\" and col in ddf_loaded.columns\n",
    "    ]  # Original features\n",
    "    feature_columns.extend(\n",
    "        [\"interaction_feature\", \"polynomial_feature\"]\n",
    "    )  # Add new ones\n",
    "\n",
    "    X_for_scaling = ddf_transformed[feature_columns]\n",
    "    y_target = ddf_transformed[\"target\"]  # This is a Dask Series\n",
    "\n",
    "    scaler = DaskStandardScaler()\n",
    "    X_scaled_lazy = scaler.fit_transform(X_for_scaling)  # X_scaled_lazy is a Dask Array\n",
    "    y_target_lazy_array = y_target.to_dask_array(\n",
    "        lengths=True\n",
    "    )  # Convert y to Dask Array\n",
    "    if y_target_lazy_array.ndim > 1:\n",
    "        y_target_lazy_array = y_target_lazy_array.ravel()\n",
    "\n",
    "    # --- Strategic Persist ---\n",
    "    # Persist only the fully preprocessed X and y that will feed into ML\n",
    "    print(\"Persisting scaled X and target y array before ML...\")\n",
    "    X_persisted = X_scaled_lazy.persist()\n",
    "    y_persisted = y_target_lazy_array.persist()\n",
    "\n",
    "    # IMPORTANT: Do NOT use dask.compute(X_persisted, y_persisted) here if you just want them on workers.\n",
    "    # .persist() itself returns Dask collections that point to data held on workers.\n",
    "    # A small operation can ensure scheduling starts if desired for observation,\n",
    "    # or use dask.distributed.wait if precise control over completion is needed.\n",
    "    # For this experiment, just letting downstream tasks trigger use of persisted data is fine.\n",
    "    print(\"X_scaled and y_target_array scheduled for persistence.\")\n",
    "\n",
    "    # Proceed with ML using the persisted collections\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_persisted,\n",
    "        y_persisted,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        shuffle=True,\n",
    "        convert_mixed_types=True,\n",
    "    )\n",
    "\n",
    "    model = DaskLinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Pipeline with strategic persist finished in: {duration:.2f} seconds\")\n",
    "    return duration\n",
    "\n",
    "\n",
    "# Run the modified pipeline experiment\n",
    "# Ensure client from Cell 7 is active, or re-initialize one (see commented code above)\n",
    "if \"client\" not in locals() or client.status == \"closed\":\n",
    "    print(\n",
    "        \"Dask client not active. Please ensure Cell 7's client is running or re-initialize.\"\n",
    "    )\n",
    "    # Handle error or re-initialize client here for robustness\n",
    "else:\n",
    "    duration_persist_exp = pipeline_with_strategic_persist(file_pattern)\n",
    "\n",
    "    if \"parallel_duration\" in locals() and parallel_duration > 0:\n",
    "        print(f\"Original parallel duration (from Cell 7): {parallel_duration:.2f}s\")\n",
    "        print(f\"Pipeline with strategic persist duration: {duration_persist_exp:.2f}s\")\n",
    "    else:\n",
    "        print(\"Original parallel duration not available for comparison.\")\n",
    "        print(f\"Pipeline with strategic persist duration: {duration_persist_exp:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Report Guidance (Placeholders for Your Text)\n",
    "# Description: Key points to cover in your 1-2 page report based on the project requirements.\n",
    "# Fill this out in a separate Markdown document or text file.\n",
    "\n",
    "# --- Report Structure Guidance ---\n",
    "\n",
    "# ## 1. Processing Task and Dataset\n",
    "#    - **Dataset Description:**\n",
    "#      - Type: Generated tabular data.\n",
    "#      - Size: Approx. 5 GB (N_FILES files, N_ROWS_PER_FILE rows/file, N_FEATURES features + 1 target).\n",
    "#      - Features: Numerical, randomly generated (`feature_0` to `feature_N-1`).\n",
    "#      - Target: Numerical, derived from features with added noise (`target`).\n",
    "#      - Generation method: `numpy.random` for features, linear combination + noise for target, saved as multiple CSVs.\n",
    "#    - **Processing Task:**\n",
    "#      - Goal: Perform a regression analysis to predict the target variable.\n",
    "#      - Transformations:\n",
    "#        1. Creation of an interaction feature (`feature_0 * feature_1`).\n",
    "#        2. Creation of a polynomial feature (`feature_2 ** 2`).\n",
    "#        3. Feature scaling using `DaskStandardScaler`.\n",
    "#      - Machine Learning:\n",
    "#        - `dask_ml.model_selection.train_test_split` for splitting data.\n",
    "#        - `dask_ml.linear_model.LinearRegression` for model training.\n",
    "#        - Evaluation using Mean Squared Error (`dask_ml.metrics.mean_squared_error`).\n",
    "\n",
    "# ## 2. Parallelism Implementation\n",
    "#    - **Where:**\n",
    "#      - Data Loading: `dask.dataframe.read_csv` reads multiple CSVs in parallel (one task per file/block).\n",
    "#      - Transformations: Element-wise operations on Dask DataFrames (e.g., `ddf['col1'] * ddf['col2']`) are parallelized per partition.\n",
    "#      - Feature Scaling: `DaskStandardScaler` computes statistics (mean, std) in parallel across partitions and then applies scaling per partition.\n",
    "#      - Train/Test Split: `dask_ml.model_selection.train_test_split` operates on Dask collections, preserving parallelism.\n",
    "#      - Model Training (`LinearRegression`): Dask-ML's Linear Regression can use parallel algorithms (e.g., direct methods involving matrix operations on Dask arrays, or iterative methods like Tall-Skinny QR that are designed for parallelism).\n",
    "#      - Prediction & Evaluation: Also performed in parallel on Dask collections.\n",
    "#    - **How:**\n",
    "#      - Dask DataFrames: Core data structure, automatically parallelizes operations across partitions.\n",
    "#      - Dask Arrays: Output of scaler and input to ML model, also support parallel operations.\n",
    "#      - Dask-ML: Provides ML algorithms that integrate with Dask collections.\n",
    "#      - Dask Distributed Scheduler: `Client(LocalCluster(...))` used to manage and distribute tasks to multiple workers/threads on a local machine.\n",
    "#      - Lazy Evaluation: Dask builds a task graph, and computations are only triggered by `.compute()`, `.persist()`, or when a Dask-ML model's `.fit()` or `.predict()` method requires results.\n",
    "\n",
    "# ## 3. Sequential vs. Parallel Performance\n",
    "#    - **Include Numbers/Graphs:**\n",
    "#      - Present the table/bar chart comparing `sequential_duration` and `parallel_duration`.\n",
    "#      - Report the speedup factor (`sequential_duration / parallel_duration`).\n",
    "#    - **Analysis:**\n",
    "#      - Discuss why the parallel version is faster (or if not, why not).\n",
    "#      - Relate to the Dask dashboard observations: e.g., \"The dashboard showed tasks for reading CSVs and applying transformations running concurrently across N workers, leading to the observed speedup in the data preprocessing phase.\"\n",
    "\n",
    "# ## 4. Amdahl's Law Discussion\n",
    "#    - **Concept:** Amdahl's Law states that the maximum speedup achievable by parallelizing a task is limited by its sequential portion. Speedup = 1 / ((1-P) + P/S), where P is the proportion of the program that can be parallelized, and S is the speedup of that portion.\n",
    "#    - **Application to Your Pipeline:**\n",
    "#      - **Inherently Sequential Parts (Bottlenecks):**\n",
    "#        - Initial script setup, Python interpreter overhead (minor).\n",
    "#        - Certain operations in `StandardScaler` (e.g., combining statistics from all partitions might have a sequential component).\n",
    "#        - Some parts of specific ML algorithms might not be perfectly parallelizable (e.g., final aggregation steps).\n",
    "#        - Communication overhead: Moving data between workers (serialization, network if not local cluster). This is not computation but adds to time.\n",
    "#        - Dask scheduler overhead: Managing the task graph.\n",
    "#        - Final result gathering: If a single result (like MSE) is computed and brought back to the client, this is a point of synchronization.\n",
    "#        - Reading metadata or very small files can sometimes be dominated by overhead rather than parallel I/O benefits.\n",
    "#      - **How these limit scalability:** Even if 95% of your workload is perfectly parallelizable, the 5% sequential part means you can't get more than a 20x speedup, regardless of how many cores you add.\n",
    "#      - \"In my pipeline, while data loading and most transformations are highly parallel, the `StandardScaler.fit()` involves computing global statistics (mean, std dev) which requires an aggregation step. This aggregation, while parallelized by Dask, still forms a synchronization point that could be a bottleneck according to Amdahl's Law. Similarly, the final steps of the linear regression solver might have components that are not perfectly scalable.\"\n",
    "\n",
    "# ## 5. Task Graph Analysis and Reflection\n",
    "#    - **Structure Observations:**\n",
    "#      - Describe the general shape of your task graphs (e.g., from `ddf.visualize()` or dashboard).\n",
    "#        \"The graph for data loading and initial transformations showed a wide structure, with parallel chains of tasks for each partition/file, followed by merging points for operations like `ddf.एमइआरजीइ` (if used) or aggregations.\"\n",
    "#      - \"The `StandardScaler().fit_transform()` likely showed a graph where initial partition-wise computations fed into an aggregation phase for statistics, then back to partition-wise scaling.\"\n",
    "#      - \"The ML fit graph would be more complex, representing the algorithm's steps.\"\n",
    "#    - **Influence of Changes (e.g., from Cell 9 experiments):**\n",
    "#      - **`.persist()`:** \"Using `.persist()` on intermediate Dask DataFrames/Arrays altered the graph execution. It added explicit tasks for computing and storing results in worker memory. On the dashboard, this appeared as a distinct computation phase. Subsequent operations on persisted data might show simpler upstream graphs as they read directly from memory, potentially speeding them up if the persisted data is accessed multiple times or if recomputing it is expensive. However, the act of persisting itself takes time and memory.\"\n",
    "#      - **Repartitioning (if experimented with):** \"Changing the number of partitions (e.g., `ddf.repartition()`) would directly alter the width of the graph. More partitions could increase parallelism but also scheduler overhead and task size granularity.\"\n",
    "#      - \"Breaking fusion by inserting `.compute()` calls would make the graph more fragmented, with Dask unable to optimize operations as effectively.\"\n",
    "\n",
    "# ## 6. Development Process and Key Challenges\n",
    "#    - **Your Process:**\n",
    "#      - \"I started by defining the data generation, then implemented the pipeline steps sequentially in concept. Then translated these to Dask API calls.\"\n",
    "#      - \"Benchmarking was done iteratively: first sequential, then parallel, then experiments.\"\n",
    "#    - **Key Challenges:**\n",
    "#      - **Understanding Lazy Evaluation:** \"Initially, it was tricky to remember that Dask operations don't execute immediately, and results need a `.compute()` or similar trigger. This affects debugging and reasoning about execution flow.\"\n",
    "#      - **Memory Management:** \"With a 5-10GB dataset, ensuring that intermediate computations or persisted data fit into worker memory was a concern. The Dask dashboard was crucial for monitoring memory usage. Naively persisting too much data could lead to 'spilling to disk' or out-of-memory errors.\"\n",
    "#      - **Interpreting the Dashboard:** \"While powerful, correlating dashboard visualizations precisely with specific lines of code or pipeline stages took some practice.\"\n",
    "#      - **Debugging:** \"Debugging errors in a distributed Dask computation can be more complex than in standard Python, as stack traces might originate from workers and involve Dask's internal scheduling.\"\n",
    "#      - **Choosing Optimal Partitions:** \"Deciding on the right number of partitions can be non-trivial. Too few limits parallelism, too many increases overhead.\"\n",
    "#      - **Data Generation Time:** \"Generating the ~5GB dataset itself took a noticeable amount of time, which is a practical consideration for pipeline development.\"\n",
    "#      - (If applicable) \"Setting up the Dask environment or specific library versions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Cleanup (Optional)\n",
    "# Description: Delete the generated data directory to free up space.\n",
    "\n",
    "\n",
    "def cleanup_generated_data():\n",
    "    if os.path.exists(DATA_DIR):\n",
    "        try:\n",
    "            shutil.rmtree(DATA_DIR)\n",
    "            print(f\"Successfully removed data directory: {DATA_DIR}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing data directory {DATA_DIR}: {e}\")\n",
    "    else:\n",
    "        print(f\"Data directory {DATA_DIR} not found. No cleanup needed.\")\n",
    "\n",
    "\n",
    "# Uncomment the line below to run the cleanup function\n",
    "# cleanup_generated_data()\n",
    "\n",
    "# Final shutdown of Dask client and cluster\n",
    "try:\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "    print(\"Dask client and cluster shut down.\")\n",
    "except NameError:\n",
    "    print(\"No active Dask client/cluster to shut down.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during final Dask shutdown: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fhnw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
